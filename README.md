# ETL_simulation
End-to-End ETL Pipeline Implementation
### ETL Project Summary

This repository contains an end-to-end ETL project that demonstrates my expertise in data engineering, including data validation, cleansing, transformation, and visualization. The project utilizes Azure Data Factory, Azure SQL Database, and Tableau to process and visualize movie rating data from diverse sources such as CSV, JSON, and XML files.

#### Key Features:
1. **Data Validation and Cleansing**:
    - Ensured data integrity and consistency by validating data types, checking for missing values, and removing duplicates.
    - Standardized formats and handled missing values using various imputation methods.

2. **Data Transformation**:
    - Implemented robust ETL processes using Azure Data Factory pipelines to extract, transform, and load data.
    - Utilized Azure Data Factory's Data Flow for real-time data transformation and cleansing.
    - Applied normalization techniques and created summary tables for aggregated data analysis.

3. **Data Loading**:
    - Designed and implemented database schemas in Azure SQL Database to store structured and semi-structured data.
    - Indexed key columns to enhance query performance and data retrieval efficiency.

4. **Data Visualization**:
    - Connected Tableau to Azure SQL Database for interactive data visualization.
    - Created dashboards to visualize movie rating trends, user activities, and other key metrics.

5. **Documentation**:
    - Provided detailed documentation of the ETL process, including data extraction, transformation rules, and loading strategies.
    - Included a user guide for navigating and interacting with Tableau dashboards.

#### Advanced Features:
- **Real-Time Data Processing**: Set up Azure Stream Analytics for processing streaming data.
- **Machine Learning Integration**: Incorporated predictive analytics using Azure Machine Learning and scikit-learn.

This project showcases my proficiency in SQL for data querying and infrastructure, Python for data manipulation, and the use of cloud resources for scalable and efficient data processing. It also highlights my ability to implement agile methodologies, ensuring continuous improvement and adaptability throughout the project lifecycle.

#### Repository Structure:
- **/data**: Contains raw data files in CSV, JSON, and XML formats.
- **/scripts**: Includes Python scripts for data validation, cleansing, and transformation.
- **/azure_pipelines**: Azure Data Factory pipeline configurations.
- **/sql_schemas**: SQL scripts for creating and indexing database tables.
- **/tableau**: Tableau workbook files for data visualization.
- **/docs**: Comprehensive documentation of the ETL process and user guide.

This ETL project is a testament to my journey from a biochemistry background to becoming a proficient data engineer, leveraging my experience in pharmaceutical manufacturing quality control and quality assurance to ensure data accuracy and reliability.
